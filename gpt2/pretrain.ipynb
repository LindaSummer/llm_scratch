{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29824f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3612,  0.4223, -0.0709,  ...,  0.3479,  0.4655, -0.2833],\n",
      "         [-0.1786, -0.5656, -0.9478,  ...,  0.0475,  0.5173, -0.3161],\n",
      "         [ 0.7118,  0.0335,  0.1078,  ...,  0.1019, -0.4330, -0.2547],\n",
      "         [-1.0068,  0.3421, -0.1191,  ...,  0.7194,  0.4018,  0.0532]],\n",
      "\n",
      "        [[-0.2562,  0.0899,  0.0337,  ...,  0.2659,  0.4448, -0.6800],\n",
      "         [ 0.1229,  0.3651, -0.2071,  ...,  0.7703,  0.2702,  0.2249],\n",
      "         [ 1.0556,  1.0312, -0.2797,  ...,  0.6933,  0.3201, -0.3172],\n",
      "         [-0.1560,  0.3924,  0.3286,  ...,  1.2626, -0.1862,  0.0392]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[2.4139e-05, 2.5660e-05, 1.5669e-05,  ..., 2.3820e-05,\n",
      "          2.6793e-05, 1.2671e-05],\n",
      "         [1.4092e-05, 9.5700e-06, 6.5296e-06,  ..., 1.7667e-05,\n",
      "          2.8262e-05, 1.2281e-05],\n",
      "         [3.4212e-05, 1.7363e-05, 1.8702e-05,  ..., 1.8591e-05,\n",
      "          1.0890e-05, 1.3016e-05],\n",
      "         [6.1391e-06, 2.3655e-05, 1.4915e-05,  ..., 3.4497e-05,\n",
      "          2.5111e-05, 1.7720e-05]],\n",
      "\n",
      "        [[1.3008e-05, 1.8387e-05, 1.7382e-05,  ..., 2.1925e-05,\n",
      "          2.6222e-05, 8.5141e-06],\n",
      "         [1.9108e-05, 2.4344e-05, 1.3737e-05,  ..., 3.6507e-05,\n",
      "          2.2139e-05, 2.1158e-05],\n",
      "         [4.8339e-05, 4.7174e-05, 1.2718e-05,  ..., 3.3649e-05,\n",
      "          2.3168e-05, 1.2249e-05],\n",
      "         [1.4363e-05, 2.4855e-05, 2.3318e-05,  ..., 5.9339e-05,\n",
      "          1.3935e-05, 1.7459e-05]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[27595],\n",
      "         [ 2463],\n",
      "         [35303],\n",
      "         [20860]],\n",
      "\n",
      "        [[37911],\n",
      "         [30882],\n",
      "         [19280],\n",
      "         [26217]]])\n"
     ]
    }
   ],
   "source": [
    "from ast import arg\n",
    "from architecture import *\n",
    "import tiktoken\n",
    "GPT_CONFIG_124M = Config()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch = [\n",
    "    torch.tensor(tokenizer.encode(txt1)),\n",
    "    torch.tensor(tokenizer.encode(txt2)),\n",
    "]\n",
    "batch = torch.stack(batch, dim=0)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# demo_config = Config(context_length=4)\n",
    "model = GPTModel(config=GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)\n",
    "probs = torch.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "argmax = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6b30b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (_tok_emd): Embedding(50257, 768)\n",
       "  (_pos_emd): Embedding(256, 768)\n",
       "  (_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (_transformers): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (_norm_1): LayerNorm()\n",
       "      (_attention): MultiHeadAttention(\n",
       "        (_w_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_w_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (_out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (_drop_1): Dropout(p=0.1, inplace=False)\n",
       "      (_norm_2): LayerNorm()\n",
       "      (_ff): FeedForward(\n",
       "        (_layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (_drop_2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (_final_norm_layer): LayerNorm()\n",
       "  (_out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M_S = Config(\n",
    "    vocab_size=50257,\n",
    "    context_length=256,\n",
    "    emb_dim=768,\n",
    "    num_heads=12,\n",
    "    num_layers=12,\n",
    "    dropout=0.1,\n",
    "    qkv_bias=False,\n",
    "    bias=False,\n",
    ")\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(config=GPT_CONFIG_124M_S)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc118eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens(text: str, tokenizer) -> torch.Tensor:\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "def tokens_to_text(tokens: torch.Tensor, tokenizer) -> str:\n",
    "    flatted_tokens = tokens.squeeze(0)\n",
    "    return tokenizer.decode(flatted_tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c36572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "from architecture import generate_text_trivial\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_trivial(\n",
    "    model=model,\n",
    "    idx=text_to_tokens(start_context, tokenizer=tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M_S.context_length,)\n",
    "\n",
    "print(\"Output text:\")\n",
    "print(tokens_to_text(token_ids, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42113df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cross_entropy(logits: torch.Tensor, target_tokens: torch.Tensor) -> torch.Tensor:\n",
    "    flatten_logits = logits.flatten(0, 1) # flatten the batch and token dim, keep the logist of each token\n",
    "    flatten_target_tokens = target_tokens.flatten(0)\n",
    "    return torch.nn.functional.cross_entropy(flatten_logits, flatten_target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5458834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 20479 characters\n",
      "Length of tokens: 5145 tokens\n",
      "Train size: 18431 characters\n",
      "Validate size: 2048 characters\n",
      "Train data:\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([  503,  4291,   262,  4252, 18250,  8812,   558,    13,   198,   198])\n",
      "y[0, :10] tensor([ 4291,   262,  4252, 18250,  8812,   558,    13,   198,   198,    40])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([12036,   683,     0,  3226,  1781,   314,  4001,   284,   466,   262])\n",
      "y[0, :10] tensor([ 683,    0, 3226, 1781,  314, 4001,  284,  466,  262, 4286])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([  438,   292,   339,   550,   587,   832,    11,   290,   287, 15275])\n",
      "y[0, :10] tensor([  292,   339,   550,   587,   832,    11,   290,   287, 15275,   286])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([  286,  1762,    30,  2011, 29483,  2540,   284,   467,   257,  1310])\n",
      "y[0, :10] tensor([ 1762,    30,  2011, 29483,  2540,   284,   467,   257,  1310,  4295])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([  271, 10899,   550,   366,  7109, 14655,   683,   866,   526,  1114])\n",
      "y[0, :10] tensor([10899,   550,   366,  7109, 14655,   683,   866,   526,  1114,  9074])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([   13,   198,   198,     1, 19242,   339,   442, 17758,   465,  5986])\n",
      "y[0, :10] tensor([  198,   198,     1, 19242,   339,   442, 17758,   465,  5986,  1165])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([ 314, 4752,  340, 6777,   13,  632,  373,  407,  326,  616])\n",
      "y[0, :10] tensor([4752,  340, 6777,   13,  632,  373,  407,  326,  616, 2583])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([ 1459,   714,  1239,   423,  4499,   326, 18680,   510,    12,  5532])\n",
      "y[0, :10] tensor([  714,  1239,   423,  4499,   326, 18680,   510,    12,  5532, 14000])\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n",
      "x[0, :10] tensor([10197,   832,   262, 46475,   286, 18113,   544,   338, 10953,   314])\n",
      "y[0, :10] tensor([  832,   262, 46475,   286, 18113,   544,   338, 10953,   314,  2936])\n",
      "Validation data:\n",
      "x: torch.Size([2, 256])\n",
      "y: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from architecture import create_dataloader\n",
    "\n",
    "file_path = \"./the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(f\"Length of text: {len(text)} characters\")\n",
    "tokens = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "print(f\"Length of tokens: {len(tokens)} tokens\")\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(text) * train_ratio)\n",
    "train_text = text[:train_size]\n",
    "validate_text = text[train_size:]\n",
    "print(f\"Train size: {len(train_text)} characters\")\n",
    "print(f\"Validate size: {len(validate_text)} characters\")\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    text=train_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_S.context_length,\n",
    "    stride=GPT_CONFIG_124M_S.context_length,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    tokenizer=tokenizer)\n",
    "validate_loader = create_dataloader(\n",
    "    text=validate_text,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M_S.context_length,\n",
    "    stride=GPT_CONFIG_124M_S.context_length,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "print(\"Train data:\")\n",
    "for x, y in train_loader:\n",
    "    print(\"x:\", x.shape)\n",
    "    print(\"y:\", y.shape)\n",
    "    print(\"x[0, :10]\", x[0, :10])\n",
    "    print(\"y[0, :10]\", y[0, :10])\n",
    "\n",
    "print(\"Validation data:\")\n",
    "for x, y in validate_loader:\n",
    "    print(\"x:\", x.shape)\n",
    "    print(\"y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17ab0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch: torch.Tensor,\n",
    "                    target_batch: torch.Tensor,\n",
    "                    model: nn.Module,\n",
    "                    device: torch.device,\n",
    "                    ) -> torch.Tensor:\n",
    "    input_batch = input_batch.to(device=device)\n",
    "    target_batch = target_batch.to(device=device)\n",
    "    logits = model(input_batch)\n",
    "    return loss_cross_entropy(logits, target_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5d6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader: DataLoader,\n",
    "                     model: nn.Module,\n",
    "                     device: torch.device,\n",
    "                     num_batches: int = 0):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches == 0:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        \n",
    "        loss = calc_loss_batch(input_batch=input, target_batch=target, model=model, device=device)\n",
    "        total_loss += loss\n",
    "        \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(validate_loader, model, device)\n",
    "    print(\"Training loss:\", train_loss)\n",
    "    print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    eval_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(data_loader=train_loader,\n",
    "                                      model=model,\n",
    "                                      device=device,\n",
    "                                      num_batches=eval_iter)\n",
    "        eval_loss = calc_loss_loader(data_loader=eval_loader,\n",
    "                                      model=model,\n",
    "                                      device=device,\n",
    "                                      num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, eval_loss\n",
    "\n",
    "\n",
    "def generate_sample(model: nn.Module,\n",
    "                    context_size: int,\n",
    "                    tokenizer,\n",
    "                    device: torch.device,\n",
    "                    start_context: str,\n",
    "                    max_new_tokens: int=50) -> str:\n",
    "    model.eval()\n",
    "    encoded = text_to_tokens(text=start_context, tokenizer=tokenizer)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_trivial(model=model,\n",
    "                                          idx=encoded,\n",
    "                                          max_new_tokens=max_new_tokens,\n",
    "                                          context_size=context_size)\n",
    "    model.train()\n",
    "    return tokens_to_text(tokens=token_ids, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model: nn.Module,\n",
    "                       train_loader: DataLoader,\n",
    "                       eval_loader: DataLoader,\n",
    "                       optimizer,\n",
    "                       device: torch.device,\n",
    "                       num_epochs: int,\n",
    "                       eval_freq: int,\n",
    "                       eval_iter: int, \n",
    "                       start_context: str,\n",
    "                       tokenizer,\n",
    "                       config: Config):\n",
    "    train_losses, eval_losses, track_token_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch=input, target_batch=target, model=model, device=device)\n",
    "            loss.backward()\n",
    "            token_seen += input.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, eval_loss = evaluate_model(model=model,\n",
    "                                                       train_loader=train_loader,\n",
    "                                                       eval_loader=eval_loader,\n",
    "                                                       device=device,\n",
    "                                                       eval_iter=eval_iter)\n",
    "                train_losses.append(train_losses)\n",
    "                eval_losses.append(eval_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\"Epoch: {epoch} (step: {global_step:06d}): \"\n",
    "                    f\"Train loss: {train_loss:.3f}, \"\n",
    "                    f\"Eval loss: {eval_loss:.3f}\"\n",
    "                    )\n",
    "        generated_text = generate_sample(model=model,\n",
    "                        context_size=config.context_length,\n",
    "                        tokenizer=tokenizer,\n",
    "                        device=device,\n",
    "                        start_context=start_context)\n",
    "        print(f\"\"\"Generated text:\n",
    "              -------------------------------\n",
    "              {generated_text}\n",
    "              -------------------------------\"\"\")\n",
    "    return train_loss, eval_loss, track_token_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "model.parameters(),\n",
    "lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "model, train_loader, validate_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "start_context=\"Every effort moves you\", tokenizer=tokenizer, config=GPT_CONFIG_124M_S\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
